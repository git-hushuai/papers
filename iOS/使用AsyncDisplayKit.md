在客户端或则前端开发中，对于性能的优化，尤其是UI，往往都不是最先考虑的问题。

因为在大多数场景下，对于性能的优化，尤其是UI，往往都不是最先考虑的问题。

因为在大多数场景下，使用更加复杂的高性能代码替代可用的代码经常会导致代码的可维护性下降，所以更需要我们开发者对优化的时间点以及原因有一个比较清楚的认识，避免过度优化带来的问题。

对iOS开发比较熟悉的开发者都知道，iOS中的性能问题大多是阻塞主线程导致用户的交互反馈出现可以感知的延迟。

详细说起来，大体有三种原因：

1. UI渲染需要的时间较长，无法按时提交结果。
2. 一些需要"密集计算"的处理被放到了主线程中执行，导致主线程被阻塞，无法渲染UI界面
3. 网络请求由于网络状态的问题响应较慢，UI层由于没有模型返回无法渲染。

上面的这些问题都会影响应用的性能，最常见的表现就是UITableView在滑动的时候没有达到60FPS，用户能感受到明显的卡顿。

##### 屏幕的渲染
屏幕的渲染可能要从CRT（Cathode ray tube）显示器和LCD（Liquid-crystal display）显示器说起。

CRT显示器是比较古老的技术，它使用阴极电子枪发射电子，在阴极高压的作用下，电子由电子枪射向荧光屏，使荧光粉发光，这也就是用磁铁靠近一些老式电视机的屏幕会让他们变色的原因。

而FPS就是CRT显示器的刷新频率，电子枪每秒会对显示器上内容进行60-100次的刷新，哪怕在我们看来没有任何变化。

但是LCD的原理与CRT非常不同，LCD的成像原理跟光学有关

+ 在不加电压下，光线会沿着液晶分子的间隙前进旋转90°，所以光可以通过。
+ 在加入电压后，光沿着液晶分子的间隙直线前进，被滤光板挡住。

LCD的成像原理虽然与CRT截然不同，每一个像素的颜色可以在需要改变时才去改变电压，也就是不需要刷新频率，但由于一些历史原因，LCD仍然需要按照一定的刷新频率向GPU获取新的图像用于显示。

通常来说，计算机系统中CPU、GPU、显示器是以上面这种方式协同工作的，CPU计算好显示内容提交到GPU，GPU渲染完成后将渲染结果放入帧缓冲区，随后视频控制器会按照VSync信号逐行读取帧缓冲区的数据，经过可能的数模转换传递给显示器显示。

在最简单的情况下，帧缓冲区只有一个，这时帧缓冲区的读取和刷新都会有比较大的销量问题，为了解决效率问题，显示系统通常会引入两个缓冲区，即双缓冲机制，在这种情况下，GPU会预先渲染好一帧放入到有个帧缓冲区内，让视频控制器读取，当下一帧渲染好后，GPU会直接把视频控制器的指针指向第二个缓冲器，如此一来效率会有很大的提升。

双缓冲虽然能解决效率问题，但会引入一个新的问题，当视频控制器还未读取完成时，即屏幕内容刚显示一半时，GPU将新的一帧内容提交到帧缓冲区并把两个缓冲区进行交换后，视频控制器就会把新的一帧数据的下半段显示到屏幕上，造成画面撕裂现象。

#### 卡顿产生的原因和解决办法

在VSync信号到来后，系统图形服务会通过CADisplayLink等机制通知App，App主线程开始在CPU中计算显示内容，比如视图的创建、布局计算、图片解码、文本绘制等，随后CPU会将计算好的内容提交到GPU去，有GPU进行变换、合成、渲染。随后GPU会把渲染结果提交到帧缓冲区中，等待下一次VSync信号到来时显示到屏幕上，由于垂直同步的机制，如果在一个VSync时间内，CPU或者GPU没有完成内容提交，则那一帧就会被丢弃，等待下一次机会再显示，而这时显示屏会保留之前的内容不变，这就是界面卡顿的原因

#### 屏幕撕裂：

显示器只是用于将图像显示在屏幕上，谁又是图像的提供者呢？图像的提供者是我们经常说的GPU提供的。而这导致了另外一个问题，由于GPU生成图像的频率与显示器刷新的频率是不相关的，那么在显示器刷新时，GPU没有准备好需要显示的图像怎么办；或者GPU的渲染速度过快，显示器来不及刷新，GPU就已经开始渲染下一帧图像又该如何处理

如果解决不了这两个问题，就会出现上图中的屏幕撕裂现象，屏幕中一部分显示的是上一帧的内容，另一部分显示的是下一帧的内容。

我们用两个例子来说明可能出现屏幕撕裂的两种情况：

+ 如果显示器的刷新频率为75HZ，GPU的渲染速度为100HZ，那么在两次屏幕刷新的间隔中，GPU会渲染4/3个帧，后面的1/3帧会覆盖已经渲染好的帧，最终会导致屏幕在1/3或者2/3的位置出现屏幕撕裂效果。
+ 那么GPU的渲染速度小于显示器呢，比如说50HZ，那么在两次屏幕刷新的间隔中，GPU只会渲染2/3帧，剩下的1/3帧会来自上一帧，与上面的结果完全相同，在同样的位置出现撕裂效果。


到这里，有人会说，如果显示器的刷新频率与GPU的渲染速度完全相同，应该就会解决屏幕撕裂的问题了吧？其实并不是，显示器从CPU拷贝帧的过程需要消耗一定的时间，如果屏幕在拷贝图像时刷新，仍然会导致屏幕撕裂问题。

引入多个缓冲区可以有效地缓解屏幕撕裂，也就是同时使用一个帧缓冲区（frame buffer）和多个设备缓冲区（back buffer）;在每次显示器请求内容时，都会从帧缓冲区中取出图像然后渲染；

虽然帧缓冲区可以减缓这些问题，但是却不能解决；如果后备缓冲区绘制完成，而帧缓冲区的图像没有被渲染，后备缓冲区中的图像就会覆盖帧缓冲区，仍然会导致屏幕撕裂。

解决这个问题需要另外一个机制的帮助，也就是垂直同步（Vertical synchronization）,简称V-Sync来解决。

##### V-Sync

V-Sync的主要作用就是保证只有在帧缓冲区中的图像被渲染之后，后备缓冲区中的内容才可以被拷贝到帧缓冲区中，理想情况下V-Sync会按这种方式工作。

![](https://img.draveness.me/2016-08-22-normal-vsync.png-1000width)

每当V-Sync发生时，CPU和GPU都已经完成了对图像的处理以及绘制，显示器可以直接拿到缓冲区中的帧，但是，如果CPU或者GPU的处理需要的时间较长，就会出现掉帧的问题。

![](https://img.draveness.me/2016-08-22-lag-vsync.png-1000width)

在V-Sync信号发出时，CPU和GPU并没有准备好需要渲染的帧，显示器就会继续使用当前帧，这就加剧了屏幕的显示问题，而每秒显示的帧数会小于60。

由于会发生很多次的掉帧，在开启了V-Sync后，40-50FPS的渲染频率意味着显示器输出画面帧率会从60FPS急剧下降到30FPS，

其实到这里关于屏幕渲染的内容就已经差不多结束；根据V-Sync的原理，优化应用性能、提高App的FPS就可以从两个方面入手，优化CPU以及GPU的处理时间。

#### CPU资源消耗原因和解决方案

##### 对象的创建

对象的创建会分配内存，调整属性，甚至还有读取文件的操作。比较消耗CPU资源，尽量用轻量的对象替代重量的对象，可以对性能有所优化，比如

+ CALayer比UIView要轻量很多，那么不需要响应触摸事件的控件，用CALayer显示会更加合适，如果对象不涉及UI操作，则尽量放到后台线程去创建，但可惜的是包含CALayer的控件，都只能在主线程创建和操作，通过Storyboard创建视图对象时，其资源消耗会比直接通过代码创建要打非常多，在性能敏感的界面里，Storyboard并不是一个好的技术选择。

尽量推迟对象创建的时间，并把对象的创建分散到多个任务中去，尽管这实现起来比较麻烦，并且带来的优势并不多，但如果能力做，还是要尽量尝试一下，如果对象可以复用，并且复用的代价比释放、创建新对象要小，那么这类对象应当尽量放到一个缓存池里复用。

##### 对象调整

对象调整也经常是消耗CPU资源的地方，这里特别说一下CALayer：CALayer内部并没有属性，当调用属性方法的时候，它内部是通过运行时resolveInstanceMethod为对象临时添加一个方法，并把对应属性值保存到内部的一个Dictionary里，同时还会通知delegate、创建动画等等，非常消耗资源，UIView的关于显示相关的属性（比如frame、bounds、transform）等实际上都是CALayer属性映射来的，所以对UIView的这些属性进行调整时，消耗的资源要远大于一般的属性。对此你在应用中，应尽量减少不必要的属性修改；

##### 对象销毁

对象的销毁虽然消耗的资源不多，但累计起来也是不能忽视的，通常当容器类持有，其销毁时的资源消耗就非常明显，同样的，如果对象可以放到后台线程中去释放，那就挪到后台线程去，这里有个小Tip，把对象捕获到block中，然后扔到后台队列去随便发送个消息以避免编译器警告，就可以让对象在后台线程销毁了。

```
NSArray *tmp = self.array;
self.array = nil;
dispatch_async(queue,^{
	[tmp class];
});
```
##### 布局计算

视图布局的计算是App中最为常见的消耗CPU资源的地方，如果能在后台线程提前计算好视图布局、并且对视图布局进行缓存，那么这个地方基本不会产生性能问题。

不论通过何种技术对视图进行布局，其最终都会落到对UIView.frame、bounds、center等属性的调整上，上面也说过，对这些属性的调整非常消耗资源，所以尽量提前计算好布局，在需要时一次性调整好属性，而不应该多次、频繁的计算和调整这些属性。

##### AutoLayout

AutoLayout 是苹果本身提倡的技术，在大部分情况下能很好的提升开发效率，但是AutoLayout对于复杂视图来说常常会产生严重的性能问题，随着视图数量的增长，AutoLayout带来的CPU消耗会呈指数上升，这部分的优化可以使用第三方ComponentKit、AsyncDisplayKit等框架

##### 文本计算

如果一个界面中包含大量文本（比如微博微信朋友圈等），文本的宽高计算会占用很大一部分资源，并且不可避免，如果对文本显示没有特殊要求，可以参考下UILabel的内部实现方式：用[NSAttributedString boundingRectWit和Size:options:context:]来计算文本宽高，用-[NSAttribbutedString drawWithRect:options:context:]来绘制文本。尽管这两个方法性能不错，但仍然需要放到后台线程进行以避免阻塞主线程;

如果你用CoreText绘制文本，那就可以先生成CoreText排版对象，然后自己计算了，并且CoreText对象还能保留以供稍后绘制使用；

##### 文本渲染

屏幕上能看到的所有文本内容控件，包括UIWebView，在底层都是通过CoreText排版、绘制为Bitmap显示的，常见的文本控件（UILabel、UITextView等）其排版和绘制都是在主线程进行的，当显示大量文本时，CPU的压力会非常大，对此解决方案只有一个，那就是自定义文本控件，用TextKit或最底层的CoreText对文本异步绘制。尽管这实现起来非常麻烦，但其带来的优势也非常大，CoreText对象创建好后，能直接获取文本的宽高信息，避免了多次计算（调整UILabel大小时算一遍、UILabel绘制时内部再算一遍）；CoreText对象占用内存较少，可以缓存下来以备稍后多次渲染。

##### 图片的解码

当你用UIImage或CGImageSource的那几个方法创建图片时，图片数据并不会立刻解码，图片设置到UIImageView或者CALayer.contents中去，并且CALayer被提交到GPU前，CGImage中的数据才会得到解码，这一步是发生在主线程的，并且不可避免，如果想绕开这个机制，常见的做法是在后台线程先将图片绘制到CGBitmapContext中，然后从BitMap直接创建图片，目前常见的网络图片库都会自带这个功能。

##### 图像的绘制

图像的绘制通常是指用那些CG开头的方法把图像绘制到画布中，然后从画布创建并显示这样一个过程，这个最常见的地方就是[UIView drawRect：]里面了，由于CoreGraphic方法通常都是线程安全的，所以图像的绘制可以很容易的放到后台线程进行，一个简单的异步绘制过程大致如下：

```
- (void)display
{
	dispatch_async(backgroundqueue,^{
		CGContextRef ctx = CGBitmapContextCreate(...);
		// draw in context
		CGImageRef img = CGBitmapContextCreateImage(ctx);
		CFRelease(ctx);
		dispatch_async(mainQueue,^{
			layer.contexts = img;
		})
	})
}

```

### GPU消耗资源原因及解决办法
相对于CPU来说，GPU能干的事情就比较单一：接收提交的纹理（Texture）和顶点描述（三角形），应用变换（transform）、混合并渲染，然后输出到屏幕上。通常你能看到的内容，主要也就是纹理（图片）和形状（三角模拟的矢量图形）两类。

###### 纹理的渲染

所有的Bitmap，包括图片、文本、栅格化的内容，最终都是要由内存提交到显存，绑定为GPU Texture。不论是提交到显存的过程，还是GPU调整和渲染Texture的过程，都要消耗不少GPU资源，当在较短时间显示大量图片时（比如TableView存在非常多的图片并且快速滑动时），CPU占用率很低，GPU占用率很高，界面仍然会掉帧，避免这种情况的办法只能是尽量减少在短时间内大量图片的显示，尽可能地将多张图片合称为一张进行显示。

当图片过大，超过GPU的最大纹理尺寸时，图片需要先由CPU进行预处理，这对CPU和GPU都会带来额外的资源消耗，目前来说，iPhone 4S以上的机型，纹理尺寸的上限都是4096\*4096。

##### 视图的混合

当多个视图（或者说CALayer）重叠在一起显示时，GPU会首先将他们混合到一起，如果视图结构过于复杂，混合的过程也会消耗很多GPU资源。为了减轻这种情况的GPU消耗，应用应当尽量减少视图数量和层次，并在不透明的视图里表明opaque属性以避免无用的Alpha通道合成。当然，这也可以用上面的方法，把多个视图预先渲染成一张图片来显示。

##### 图形的合成

CALayer 的border、圆角、阴影、遮罩（mask），CASharpLayer的矢量图像显示，通常会触发离屏渲染（offscreen rendering），而离屏渲染通常发生在GPU中，当一个列表视图中出现大量圆角的CALayer，并且快速滑动时，可以观察到GPU资源已经占满，而CPU资源消耗很少，这时界面仍然能正常滑动，但平均帧数会降到很低，为了避免这种情况，可以尝试开启CALayer.shouldRasterize属性，


##### 性能调优的策略


GPU和CPU在每次V-Sync时间点到达之前都干了什么？如果，我们知道了它们各自负责的工作，通过优化代码就可以提升性能。


很多CPU的操作都会延迟GPU开始渲染的时间：

+ 布局的计算-如果你的视图层级太过于复杂，或者视图需要重复多次进行布局，尤其是在使用Auto Layout进行自动布局时，对性能影响尤为严重。

+ 视图的懒加载-在iOS中只有当视图控制器的视图显示到屏幕时才会加载；
+ 解压图片-iOS通常会在真正绘制时才会解压图片，对于一个较大的图片，无论是直接或间接使用UIImageView或者绘制到Core Graphics中，都需要对图片进行解压；

宽泛的说，大多数的CALayer的属性都是由GPU来绘制的，比如图片的圆角、变换、应用纹理；但是过多的几何结构、重绘、离屏渲染以及过大图片的解压都会导致GPU的性能明显降低；

AsyncDisplayKit（ASDK）是由Facebook开源的一个iOS框架，能够帮助最复杂的UI界面保持流畅和快速响应。

ASDK从开发到开源大约经历了一年多的时间，他其实并不是一个简单的框架，更像是对UIKit的重新实现，把整个UIKit和CALayer层封装成一个一个Node，将昂贵的渲染、图片解码、布局及其他UI操作移出主线程。这样主线程就可以对用户的操作及时做出反应。

在ASDK中最基本的单位就是ASDisplayNode，每一个node都是对UIView以及CALayer的抽象。但是与UIView不同的是，ASDisplayNode是线程安全的，它可以在后台线程中完成初始化以及配置工作。

###### ASDK将耗时的CPU操作以及GPU纹理渲染（Texture）的过程全部放入后台线程，使主线程能够快速响应用户操作。

ADK通过独特的渲染技巧、代替AutoLayout的布局系统、智能的预加载方式等模块来实现对App性能的优化。

#####1.ASDK的渲染过程

ASDK中的渲染围绕ASDisplayNode进行，其过程总共有四条线程：

+ 初始化ASDisplayNode对应的UIView或者CALayer；
+ 在当前视图进入视图层级的时候去执行setNeedsDisplay；
+ display方法执行时，向后台线程派发绘制事务；
+ 注册成为RunLoop观察者，在每个RunLoop结束时回调；

总结：

ASDK对于绘制过程的优化有三部分：分别是栅格化子视图、绘制图像以及绘制文字。它拦截了视图加入层级时发出的通知-WillMoveToWindow：方法，然后手动调用-setNeedDisplay,强制所有的CALayer执行-display更新内容；
然后将上面的操作全部抛入了后台的并发线程中，并在RunLoop中注册回调，

